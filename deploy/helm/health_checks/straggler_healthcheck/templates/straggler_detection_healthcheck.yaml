# Copyright 2024 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# yamllint disable
{{- $guid := default (lower (randAlphaNum 8)) .Values.job.guid -}}
{{- $check_time := default (printf "%s" (now | unixEpoch)) .Values.job.check_time -}}
{{- $base_name := default "chs-hc" .Values.job.base_name -}}
{{- $unique_suffix := printf "%s-%s" $guid $check_time -}}
{{- $hc_name := printf "%s" .Values.health_check.name -}}
{{- $extra_info_leader := printf "leader" -}}
{{- $unique_leader_name := printf "%s-%s-%s-%s" $base_name $hc_name $extra_info_leader $unique_suffix | replace "_" "-"  -}}
{{- $unique_name := printf "%s-%s-%s" $base_name $hc_name $unique_suffix | replace "_" "-"  -}}
{{- $unique_svc_name := printf "%s-%s-headless-svc-%s" $base_name $hc_name $unique_suffix | replace "_" "-"  -}}
{{- $expiry_time := int (sub  $check_time (mul .Values.health_check.env.HEALTH_VALIDITY_HOURS 60 60)) -}}
---
apiVersion: v1
kind: Service
metadata:
  name: {{ $unique_svc_name | quote }}
spec:
  selector:
    name: {{ $unique_leader_name | quote }}
  clusterIP: None
  ports:
  - name: sd-leader
    port: 2379
---
{{- $node_count := $.Values.health_check.env.N_NODES | int -}}
{{- $root := . -}}
{{- range $node_index, $element := until $node_count }}
{{- $unique_node_name := printf "%s-%s-node%d-%s" $base_name $hc_name $node_index $unique_suffix | replace "_" "-"  }}
apiVersion: batch/v1
kind: Job
metadata:
  name: {{ $unique_node_name | quote }}
  namespace: default
spec:
  completions: 1
  parallelism: 1
  completionMode: Indexed
  template:
    metadata:
      labels:
        {{- if ne $node_index 0 -}}
         name: {{ $unique_name | quote}}
        {{- end }}
        {{- if eq $node_index 0 }}
         name: {{ $unique_leader_name | quote }}
        {{- end }}
    spec:
      serviceAccountName: {{ $unique_name | quote }}
      restartPolicy: Never
      hostNetwork: true
      dnsPolicy: ClusterFirstWithHostNet
      hostname: {{ $unique_node_name | quote }}
     {{- if ne $node_index 0 }}
      subdomain: {{ $unique_name | quote}}
      {{- end }}
      {{- if eq $node_index 0 }}
      subdomain: {{ $unique_leader_name | quote }}
      {{- end }}
      {{- if $.Values.health_check.params.nodesPerSuperblock -}}
      {{$superblock_number :=  div $node_index $.Values.health_check.params.nodesPerSuperblock | int}}
      nodeSelector:
        superblock: "{{$superblock_number}}"
      {{- end }}
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: cloud.google.com/gke-accelerator
                operator: Exists
                # It will trigger if label value is older than 24 hours (default) ago
                # or label does not exists.
              - key: aiinfra/straggler-healthcheck-runtime-sec
                operator: Lt
                values:
                - "{{$expiry_time}}"
              - key: aiinfra/node-not-ready
                operator: DoesNotExist
              # If label is true then it will trigger
              - key: {{ $.Values.health_check.test_label.name | quote }}
                operator: In
                values:
                - {{ $.Values.health_check.test_label.value | quote }}
            - matchExpressions:
              - key: cloud.google.com/gke-accelerator
                operator: Exists
              - key: aiinfra/straggler-healthcheck-runtime-sec
                operator: DoesNotExist
              - key: aiinfra/node-not-ready
                operator: DoesNotExist
              # If label is true then it will trigger
              - key: {{ $.Values.health_check.test_label.name | quote }}
                operator: In
                values:
                - {{ $.Values.health_check.test_label.value | quote }}
          # prefer rule with higher weight
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 50
            preference:
              matchExpressions:
              - key: aiinfra/straggler-healthcheck-runtime-sec
                operator: DoesNotExist
          - weight: 1
            preference:
              matchExpressions:
              - key: aiinfra/straggler-healthcheck-runtime-sec
                operator: Lt
                values:
                - "{{ $expiry_time }}"
      tolerations:
      - operator: "Exists"
      - key: "components.gke.io/gke-managed-component"
        operator: "Equal"
        value: "true"
        effect: "NoSchedule"
      volumes:
      - name: nvidia-install-dir-host
        hostPath:
          path: /home/kubernetes/bin/nvidia/lib64
      - name: shared-memory
        emptyDir:
          medium: "Memory"
          sizeLimit: 200Gi
      - name: tcpxo-socket
        hostPath:
          path: /run/tcpxo
      - name: var-lib
        hostPath:
          path: /var/lib
      - name: library-dir-host
        hostPath:
          path: /home/kubernetes/bin/nvidia
      - name: tcpxo-host-volume
        emptyDir: {}
      - name: tcpxo-var-volume
        hostPath:
          path: /var/lib/tcpxo/lib64
      - name: workload-terminated-volume
        emptyDir: {}
      - name: usr-local-gib
        hostPath:
          path: /home/kubernetes/bin/gib
      {{- if eq $root.Values.health_check.env.INSTANCE_TYPE "a3-highgpu-8g" }}
      - name: tcpd-socket
        hostPath:
          path: /run/tcpx
      - name: tcpx-nccl-plugin-volume
        emptyDir: {}
      - name: varlog
        emptyDir: {}
      {{- end }}
      initContainers:
      - image: "ubuntu"
        name: pre-installation
        securityContext:
          privileged: true
        command:
        - nsenter
        - -at
        - '1'
        - --
        - sh
        - -c
        - apt-get update && apt-get install --yes --no-install-recommends iptables && /sbin/iptables -I INPUT -p tcp -m tcp -j ACCEPT
      - name: tcpxo-nccl-plugin-installer
        image: {{ $.Values.health_check.ncclPlugin.image }}:{{ $.Values.health_check.ncclPlugin.tag }}
        imagePullPolicy: Always
        volumeMounts:
        - name: var-lib
          mountPath: /var/lib
        - name: library-dir-host
          mountPath: /usr/local/nvidia
        - name: usr-local-gib
          mountPath: /usr/local/gib
        {{- if eq $root.Values.health_check.env.INSTANCE_TYPE "a3-highgpu-8g" }}
        - name: "tcpx-nccl-plugin-volume"
          mountPath: "/usr/local/tcpx"
        - name: varlog
          mountPath: /var/log
        {{- end }}
        resources:
          requests:
            cpu: 150m
        command:
          - /bin/sh
          - -c
          - |
            set -ex
            chmod 755 /scripts/container_entry.sh
            /scripts/container_entry.sh install --install-nccl
            {{- if eq $root.Values.health_check.env.INSTANCE_TYPE "a3-ultragpu-8g" }}
            cp -R /var/lib/gib/. /usr/local/gib
            echo " installation finishes"
            {{- else if eq $root.Values.health_check.env.INSTANCE_TYPE "a3-megagpu-8g"}}
            mkdir -p /usr/local/nvidia/lib64
            cp -r /var/lib/tcpxo/lib64/. /usr/local/nvidia/lib64
            echo " installation finishes"
            {{- else if eq $root.Values.health_check.env.INSTANCE_TYPE "a3-highgpu-8g"}}
            cp -R /var/lib/tcpx/. /usr/local/tcpx
            echo " installation finishes"
            {{- end }}
      containers:
      {{- if $.Values.health_check.params.use_fastrak}}
      - name: tcpd-daemon
        image: {{ printf "%s:%s" $.Values.health_check.rxdm.image $.Values.health_check.rxdm.tag | quote }}
        imagePullPolicy: Always
        command:
        - "bash"
        - "-c"
        - |
          set -ex
          chmod 755 /fts/entrypoint_rxdm_container.sh
          /fts/entrypoint_rxdm_container.sh --num_hops=2 --num_nics=8  --uid= --alsologtostderr &
          while [ ! -e "/usr/share/nemo/workload_terminated" ]; do sleep 10; done
          pkill -e "^"tcpgpudmarxd || true
          sleep 30
        securityContext:
          privileged: true
          capabilities:
            add:
              - SYS_ADMIN
              - SYS_PTRACE
              - IPC_LOCK
        volumeMounts:
        - name: nvidia-install-dir-host
          mountPath: /usr/local/nvidia/lib64
        - name: tcpxo-var-volume
          mountPath: /usr/local/fastrak/lib64
        - name: tcpxo-socket
          mountPath: /tmp
        - name: workload-terminated-volume
          mountPath: /usr/share/nemo
        env:
        - name: LD_LIBRARY_PATH
          value: /usr/local/fastrak/lib64:/usr/local/nvidia/lib64
      {{- end }}
      {{- if eq $root.Values.health_check.env.INSTANCE_TYPE "a3-highgpu-8g" }}
      - name: tcpd-daemon
        image: {{ printf "%s:%s" $.Values.health_check.rxdm.image $.Values.health_check.rxdm.tag | quote }}
        imagePullPolicy: Always
        command:
        - "bash"
        args:
        - "-c"
        - |
          /tcpgpudmarxd/build/app/tcpgpudmarxd --gpu_nic_preset a3vm --gpu_shmem_type fd --setup_param "--verbose 128 2 0" --uds_path /run/tcpx &
          cleanup() {
            echo "Received SIGTERM or workload terminated, starting cleanup..."
            pkill -e "^"tcpgpudmarxd || true
            exit 0
          }
          trap cleanup SIGTERM
          while [ ! -e "/usr/share/nemo/workload_terminated" ]; do sleep 1; done
          cleanup
          sleep 10
        volumeMounts:
        - name: nvidia-install-dir-host
          mountPath: /usr/local/nvidia/lib64
        - name: tcpx-nccl-plugin-volume
          mountPath: /usr/local/tcpx
        - name: tcpd-socket
          mountPath: /run/tcpx
        - name: workload-terminated-volume
          mountPath: /usr/share/nemo
        env:
        - name: LD_LIBRARY_PATH
          value: usr/local/nvidia/lib64
        securityContext:
          privileged: true
      {{- end }}
      - name: straggler-detection-test
        image: {{ printf "%s:%s" $.Values.health_check.image.repo $.Values.health_check.image.tag | quote }}
        imagePullPolicy: Always
        securityContext:
          privileged: true
          capabilities:
            add:
              - SYS_ADMIN
              - SYS_PTRACE
              - IPC_LOCK
              {{- if $.Values.health_check.params.use_fastrak}}
              - NET_ADMIN
              {{- end }}
        env:
          - name: NODE_NAME
            valueFrom:
              fieldRef:
                fieldPath: spec.nodeName
          - name: NODE_IP
            valueFrom:
              fieldRef:
                fieldPath: status.hostIP
          {{range $key, $value := $.Values.health_check.ncclPlugin.envs}}
          - name: {{ $key }}
            value: "{{ $value }}"
          {{- end }}
          {{- range $key, $value := $.Values.health_check.env }}
          - name: {{ $key | quote }}
            value: {{ $value | quote }}
          {{- end }} {{- /* end iteration over .env */}}
          - name: NCCL_DEBUG
            value: "{{$.Values.health_check.params.debug}}"
          - name: NCCL_DEBUG_SUBSYS
            value: "{{$.Values.health_check.params.debug_subsys}}"
          - name: GCS_BUCKET
            value: "{{$.Values.health_check.env.GCS_BUCKET_NAME}}"
          - name: NODE_RANK
            value: "{{ $node_index }}"
          - name: CONTROLLER_ADDR
            value: {{ $unique_svc_name | quote }}
          - name: BM_WAIT_TIME
            value: "{{ $.Values.health_check.params.bm_wait_time }}"
          - name: JOB_TIMESTAMP
            value: {{ $check_time | quote }}
          - name: USE_FASTRAK
            value: "{{ $.Values.health_check.params.use_fastrak }}"
          {{- if eq $root.Values.health_check.env.INSTANCE_TYPE "a3-megagpu-8g" }}
          - name: LD_LIBRARY_PATH
            value: /usr/local/nvidia/lib64:/usr/local/fastrak/lib64
          {{- else if eq $root.Values.health_check.env.INSTANCE_TYPE "a3-ultragpu-8g"}}
          - name: LD_LIBRARY_PATH
            value: /usr/local/gib/lib64:/usr/local/nvidia/lib64/
          {{- else if eq $root.Values.health_check.env.INSTANCE_TYPE "a3-highgpu-8g"}}
          - name: LD_LIBRARY_PATH
            value: /usr/local/nvidia/lib64
          {{- end }}
          - name: BIDIRECTIONAL
            value: "{{$root.Values.health_check.params.bidirectional}}"
          - name: MESSAGE_SIZES_MB
            value: "{{$root.Values.health_check.params.message_sizes_mb}}"
          - name: N_BATCH
            value: "{{$root.Values.health_check.params.n_batch}}"
          - name: N_MICROBATCH
            value: "{{$root.Values.health_check.params.n_microbatch}}"
          {{- if eq $node_index 0}}
          - name: "HOSTS_CSV"
            value: {{ $.Values.health_check.params.hosts_csv | quote }}
          - name: INTERESTING_EVENT_OFFSET
            value: "{{ $.Values.health_check.params.interesting_event_offset }}"
          {{- end }}
        volumeMounts:
          - name: nvidia-install-dir-host
            mountPath: /usr/local/nvidia/lib64
          {{- if $.Values.health_check.params.use_fastrak }}
          - name: tcpxo-host-volume
            mountPath: /usr/local/fastrak/lib64
          - name: tcpxo-socket
            mountPath: /tmp
          {{- end }}
          - name: shared-memory
            mountPath: /dev/shm
          - name: workload-terminated-volume
            mountPath: /usr/share/nemo
          {{- if eq $root.Values.health_check.env.INSTANCE_TYPE "a3-ultragpu-8g" }}
          - name: usr-local-gib
            mountPath: /usr/local/gib
          - name: library-dir-host
            mountPath: /usr/local/nvidia
          {{- end }}
          {{- if eq $root.Values.health_check.env.INSTANCE_TYPE "a3-highgpu-8g" }}
          - name: tcpx-nccl-plugin-volume
            mountPath: /usr/local/tcpx
          - name: tcpd-socket
            mountPath: /run/tcpx
          - name: varlog
            mountPath: /var/log
          {{- end }}  
        resources:
          limits:
            nvidia.com/gpu: !!int 8
---
{{- end }}
apiVersion: v1
kind: ServiceAccount
metadata:
  name: {{ $unique_name | quote }}
  namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: {{ $unique_name | quote }}
rules:
- apiGroups: ["", "apps", "rbac.authorization.k8s.io", "batch"]
  resources: ["daemonsets", "serviceaccounts", "clusterrolebindings", "clusterroles", "nodes", "jobs", "pods", "services"]
  verbs: ["list", "get", "create", "delete", "watch", "patch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: {{ $unique_name | quote }}
  namespace: default
subjects:
- kind: ServiceAccount
  name: {{ $unique_name | quote }}
  namespace: default
roleRef:
  kind: ClusterRole
  name: {{ $unique_name | quote }}
  apiGroup: rbac.authorization.k8s.io